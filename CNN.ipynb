{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['font.family'] = 'serif'\n",
    "plt.rcParams['font.serif'] = 'Ubuntu'\n",
    "plt.rcParams['font.monospace'] = 'Ubuntu Mono'\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.rcParams['axes.labelsize'] = 11\n",
    "plt.rcParams['axes.labelweight'] = 'bold'\n",
    "plt.rcParams['axes.titlesize'] = 12\n",
    "plt.rcParams['xtick.labelsize'] = 9\n",
    "plt.rcParams['ytick.labelsize'] = 9\n",
    "plt.rcParams['legend.fontsize'] = 11\n",
    "plt.rcParams['figure.titlesize'] = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def read_images(parent_dir):\n",
    "    images = np.vstack([np.asarray([imresize(imread(os.path.join(parent_dir,sdir,name)),(300,300))\n",
    "                              for name in os.listdir(os.path.join(parent_dir,sdir))]) \n",
    "                                    for sdir in os.listdir(parent_dir)])\n",
    "    n_subdir_files = np.asarray([len(os.listdir(os.path.join(parent_dir,sdir))) \n",
    "                                 for sdir in os.listdir(os.path.join(parent_dir))])\n",
    "    labels = np.hstack([np.repeat(i,n_subdir_files[i],axis = 0) for i in range(len(n_subdir_files))])\n",
    "    return images, labels\n",
    "\n",
    "def save_dataset(images,labels):\n",
    "    #NOTE: by default numpy add extension \".npy\" to file name\n",
    "    np.save(\"images\",images)\n",
    "    np.save(\"labels\",labels)\n",
    "    \n",
    "def load_dataset(fimage,flabel):\n",
    "    images = np.load(fimage)\n",
    "    labels = np.load(flabel)\n",
    "    return images, labels\n",
    "\n",
    "def plot_random_images(images,labels,nimg = 4):\n",
    "    sample_images = np.random.choice(labels,nimg)\n",
    "    fig, asx = plt.subplots(nrows=1,ncols=nimg, figsize=(20,20),dpi = 800)\n",
    "    for i in range(len(asx)):\n",
    "        asx[i].imshow(images[sample_images[i]])\n",
    "        asx[i].grid(False)\n",
    "    plt.show()\n",
    "    \n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parent_dir = \"Images\"\n",
    "images,labels = read_images(parent_dir)\n",
    "plot_random_images(images,labels)\n",
    "labels = one_hot_encode(labels)\n",
    "\n",
    "#----Optionally save the numpy array to a file for later reuse----#\n",
    "#save_dataset(images,labels)\n",
    "#images, labels = load_dataset(\"images.npy\",\"labels.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev = 0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(1.0, shape = shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x,W, [1, 2, 2, 1], padding='SAME')\n",
    "\n",
    "def apply_conv(x,kernel_size,num_channels,depth):\n",
    "    weights = weight_variable([kernel_size, kernel_size, num_channels, depth])\n",
    "    biases = bias_variable([depth])\n",
    "    return tf.nn.relu(tf.add(conv2d(x, weights),biases))\n",
    "\n",
    "def apply_max_pool(x,kernel_size,stride_size):\n",
    "    return tf.nn.max_pool(x, ksize=[1, kernel_size, kernel_size, 1], \n",
    "                          strides=[1, stride_size, stride_size, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rnd_indices = np.random.rand(len(labels)) < 0.70\n",
    "\n",
    "train_x = images[rnd_indices]\n",
    "train_y = labels[rnd_indices]\n",
    "test_x = images[~rnd_indices]\n",
    "test_y = labels[~rnd_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 300\n",
    "num_labels = 2\n",
    "num_channels = 3\n",
    "\n",
    "batch_size = 5\n",
    "kernel_size = 14\n",
    "depth = 50\n",
    "num_hidden = 500\n",
    "\n",
    "learning_rate = 0.1\n",
    "dropout = 0.9\n",
    "training_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, shape=[None,image_size,image_size,num_channels])\n",
    "Y = tf.placeholder(tf.float32, shape=[None,num_labels])\n",
    "#X_ = tf.reshape(X, [-1,image_size,image_size,num_channels])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "c_1 = apply_conv(X,kernel_size,num_channels,depth)\n",
    "p_1 = apply_max_pool(c_1,4,4)\n",
    "\n",
    "c_2 = apply_conv(p_1,10,depth,depth)\n",
    "p_2 = apply_max_pool(c_2,4,4)\n",
    "\n",
    "c_3 = apply_conv(p_2,2,depth,depth)\n",
    "c_4 = apply_conv(c_3,1,depth,depth)\n",
    "\n",
    "\n",
    "#------------------------------------------------------------------------------------#\n",
    "\n",
    "shape = c_4.get_shape().as_list()\n",
    "c_4_flat = tf.reshape(c_4, [-1, shape[1] * shape[2] * shape[3]])\n",
    "\n",
    "f_weights = weight_variable([shape[1] * shape[2] * depth, num_hidden])\n",
    "f_biases = bias_variable([num_hidden])\n",
    "f = tf.nn.sigmoid(tf.add(tf.matmul(c_4_flat, f_weights),f_biases))\n",
    "#f = tf.nn.dropout(f, dropout)\n",
    "\n",
    "out_weights = weight_variable([num_hidden, num_labels])\n",
    "out_biases = bias_variable([num_labels])\n",
    "y_ = tf.nn.softmax(tf.matmul(f, out_weights) + out_biases)\n",
    "\n",
    "#------------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cross_entropy = -tf.reduce_sum(Y * tf.log(y_))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_,1), tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cost_history = np.empty(shape=[1],dtype=float)\n",
    "\n",
    "with tf.Session() as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "\n",
    "    for epoch in range(training_epochs):    \n",
    "        offset = (epoch * batch_size) % (train_y.shape[0] - batch_size)\n",
    "        batch_x = train_x[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = train_y[offset:(offset + batch_size), :]\n",
    "        \n",
    "        _, c = session.run([optimizer, cross_entropy],feed_dict={X: batch_x, Y : batch_y})\n",
    "        cost_history = np.append(cost_history,c)\n",
    "    \n",
    "    print('Test accuracy: ',session.run(accuracy, feed_dict={X: test_x, Y: test_y}))\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    plt.plot(cost_history)\n",
    "    plt.axis([0,training_epochs,0,np.max(cost_history)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
